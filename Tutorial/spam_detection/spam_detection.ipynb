{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "74ce54a9-4922-422b-af15-edcc0c107e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "164ae1b1-720f-4ae5-a3c7-ac5270d322fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                            message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('SMSSpamCollection.txt', sep='\\t', names=['label', 'message'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "441462d6-8db6-4d85-b91a-367aebc39534",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d958cb7-f490-4cb1-9ad9-f4c1c67f8c8f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "063b5ab6-d096-449d-868e-ff620441f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(df['label'])\n",
    "y=y.iloc[:,1]\n",
    "X=df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4f1defb-277a-4267-9c69-bec320340833",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be844a9c-539d-4173-8b4b-ac3624346d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "def clean_data(docs):\n",
    "    corpus = []\n",
    "    for doc in docs:\n",
    "        review = re.sub('[^a-zA-Z0-9]', ' ', doc)\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [stemmer.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "685175a8-ed0a-43de-9de0-a7c3aa9342b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_data(X_train)\n",
    "X_test = clean_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5989dc35-f2b4-4a76-b3cd-1b1c72501976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bag of words model\n",
    "cv = CountVectorizer(max_features=2500, binary=True, ngram_range=(1,2))\n",
    "X_train = cv.fit_transform(X_train).toarray()\n",
    "X_test = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5f92718-6ae9-4575-a3e1-65304bb56484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8260c140-d7e2-472f-a4a9-342d93edefe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8f7d6f6-428b-43a5-9c62-aa36412f87fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9847533632286996"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43e1b4e8-ae27-41b3-ab1e-bc6851ee53ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       955\n",
      "           1       0.97      0.93      0.95       160\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.96      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44506b00-248e-4116-8282-e5cddc57f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating bag of words model\n",
    "cv = CountVectorizer(max_features=2500, binary=True, ngram_range=(1,2))\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef410011-779d-47d8-a77b-7b29fbfbda06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding for y\n",
    "y=pd.get_dummies(df['label'])\n",
    "y=y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a143a70c-8ca0-4b86-9b3f-c9cf1df4e539",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4a1a637-a3fc-447a-9c42-423e65211a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e94032b1-b6bf-4809-9511-845fd1da9b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b1afdc-e84a-465f-9c2e-2ab0e84cfd52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9856502242152466"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48e4e520-0128-4dcb-9f2d-77aaccb2a40e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       955\n",
      "           1       0.97      0.93      0.95       160\n",
      "\n",
      "    accuracy                           0.99      1115\n",
      "   macro avg       0.98      0.96      0.97      1115\n",
      "weighted avg       0.99      0.99      0.99      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a03b81e-43ce-4ddf-a41e-6f3f056c6c9d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3a9ecea-db05-4819-9397-4b7dc2719648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df['label'])\n",
    "y = y.iloc[:,1].values\n",
    "X=df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3dc57698-56f9-4386-8fcc-2fc8557a21e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "153374c7-f02e-414c-a4b9-721cdb7e9b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "def clean_data(docs):\n",
    "    corpus = []\n",
    "    for doc in docs:\n",
    "        review = re.sub('[^a-zA-Z0-9]', ' ', doc)\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [stemmer.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeaa1346-c7e9-4a37-b3cd-0f24dd9c4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_data(X_train)\n",
    "X_test = clean_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0c285ca-f831-4e42-ba50-6afaaa7cd935",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(max_features=2500, binary=True, ngram_range=(1,2))\n",
    "X_train = tv.fit_transform(X_train).toarray()\n",
    "X_test = tv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3db70f31-2a11-4716-969e-812f934c5c27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d586ddb-5d45-46a4-9334-178b18891acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "743038c1-7ed9-41e7-94cc-fa164d878d04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9838565022421525"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2215c395-3f61-461b-a1e8-9b49386113e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       955\n",
      "           1       1.00      0.89      0.94       160\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.94      0.97      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2141dec3-9b69-4213-badf-0d50f8741dcc",
   "metadata": {},
   "source": [
    "### Word2Vec Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6b139e7b-ae78-4c9e-97b4-8e7e889f28b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(df['label'])\n",
    "y = y.iloc[:,1].values\n",
    "X = df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "18d00b9f-ea88-41fa-a0cd-da952f6ada4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "aacfb239-bffa-47b5-85b6-50372ab0a039",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = clean_data(X_train)\n",
    "X_test = clean_data(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "179d00ea-8111-4d40-bb8f-e89076c5e4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train[list(map(lambda x: len(x)>0 ,X_train))]\n",
    "X_train = [doc for doc in X_train if doc != '']\n",
    "y_test = y_test[list(map(lambda x: len(x)>0 ,X_test))]\n",
    "X_test = [doc for doc in X_test if doc != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f583a533-ce1f-4f52-aeca-3c3bd0748c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess(corpus):\n",
    "#     words = []\n",
    "#     # for sent in corpus:\n",
    "#         # sent_token = sent_tokenize(sent)\n",
    "#     for sent in corpus:\n",
    "#         words.append(simple_preprocess(sent, min_len=0, max_len=10000))\n",
    "#     return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a551b13f-d9f6-4ce8-860d-30c39394954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = preprocess(X_train)\n",
    "# X_test = preprocess(X_test)\n",
    "# len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "49219b66-b892-479e-8540-b02c904d10a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(X_train, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "851f3226-7025-4916-a4f2-65e64dc5ce53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4451"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "a257ecb1-b00e-4c5a-81c6-b93d98995275",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):\n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "085f0ad2-21df-4a01-b366-8e31be485614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4451/4451 [00:01<00:00, 4285.29it/s]\n",
      "100%|██████████| 1113/1113 [00:00<00:00, 5306.23it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_new=[]\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    X_train_new.append(avg_word2vec(X_train[i]))\n",
    "X_test_new=[]\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    X_test_new.append(avg_word2vec(X_test[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "2f2483b2-3b3b-4a16-8f89-a87393715c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the final independent features\n",
    "df_train=pd.DataFrame()\n",
    "for i in range(0,len(X_train_new)):\n",
    "    df_train=df_train.append(pd.DataFrame(X_train_new[i].reshape(1,-1)),ignore_index=True)\n",
    "df_train['output'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c9eca60a-aa76-4875-8651-75d1052e5932",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this is the final independent features\n",
    "df_test=pd.DataFrame()\n",
    "for i in range(0,len(X_test_new)):\n",
    "    df_test=df_test.append(pd.DataFrame(X_test_new[i].reshape(1,-1)),ignore_index=True)\n",
    "df_test['output'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "f5f0f40e-0951-4726-8186-dd66b6cb769a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9f760798-129e-45eb-9799-c837eed6d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "c6d27538-1aa0-4841-bf3d-03772bd96afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('output', axis=1)\n",
    "y_train = df_train['output']\n",
    "X_test = df_test.drop('output', axis=1)\n",
    "y_test = df_test['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "46653d1e-be65-4dea-ba6c-0df1e2dcc367",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3d0aeb68-33d3-478b-ac77-f52a7ec17df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e6a491b8-6b9a-4162-b789-ccca41045b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9335130278526504"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "52879b93-85d4-4682-b58a-fc700c95c215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       953\n",
      "           1       0.88      0.62      0.73       160\n",
      "\n",
      "    accuracy                           0.93      1113\n",
      "   macro avg       0.91      0.81      0.85      1113\n",
      "weighted avg       0.93      0.93      0.93      1113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf9271f-decd-4ff8-9aed-6d19161b0a4e",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "610b6ddb-8428-436c-b16b-bab46887d978",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b4320a1f-bcb1-4890-8f31-c17ec799ca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "corpus = []\n",
    "for i in range(len(df)):\n",
    "    review = re.sub('[^a-zA-Z0-9]', ' ', df['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7ea84223-1462-4e73-bb61-cf125fc8e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for sent in corpus:\n",
    "    sent_token = sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "        words.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f010b68d-46af-49fd-b563-bc0bdef27c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(words, window=5, min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6638fe8-92a9-4978-a591-cbc3a59610fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a150202-99b4-47f0-b866-b6ff66919262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5565"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3417b2fe-6ee6-47ec-b7e2-cadd1c06ff34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5cc28d63-64c2-4296-b3a4-f47aba24724f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('claim', 0.9993249773979187),\n",
       " ('call', 0.9992669224739075),\n",
       " ('cash', 0.9991850256919861),\n",
       " ('line', 0.999115526676178),\n",
       " ('draw', 0.9990968704223633),\n",
       " ('show', 0.999061644077301),\n",
       " ('number', 0.9990454912185669),\n",
       " ('contact', 0.9990395307540894),\n",
       " ('please', 0.9989975690841675),\n",
       " ('urgent', 0.9989927411079407)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('prize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6836b1ce-e2e2-47ad-9451-c78ce4030a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['prize'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2a1fdd-fc37-4cd6-9723-a629c4d18d84",
   "metadata": {},
   "source": [
    "###  AVGWord2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "98108d53-bca3-4a8f-b904-ff4235ff29b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_word2vec(doc):\n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c4c910c6-7d21-4b57-8d11-36d2f3ff2643",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5565 [00:00<?, ?it/s]C:\\Users\\USER\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\USER\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|██████████| 5565/5565 [00:02<00:00, 2384.63it/s]\n"
     ]
    }
   ],
   "source": [
    "#apply for the entire sentences\n",
    "X=[]\n",
    "for i in tqdm(range(len(words))):\n",
    "    X.append(avg_word2vec(words[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
